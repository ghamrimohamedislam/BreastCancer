# BreastCancer
# 1 - Mask file generation
Mask file is the ground truth for model training. Mask file has the exact same dimensions as its corresponding WSI image. Mask file is a binary file with normal tissue coded as ‘0’ and tumor tissue coded as ‘1’ for each corresponding pixel of WSI image.
However, the code provided by the organizer is misleading. The mask file generated by the code from their paper is all ‘0’; then another piece of code suggested generated mask file that can be open only by ASAP GUI, not by its command line and OpenSlide.
Time consuming

<img width="534" alt="M1" src="https://github.com/ghamrimohamedislam/BreastCancer/assets/124634951/1d00c42f-cc0e-4c88-9355-43648a642bea">

# 2 - Image Preprocess
# 2.1 Image Segmentation
To reduce computation, the blank regions (no tissue) on slide will be excluded : 
   Color space switch to HSV
   Tissue region segmentation (Otsu’s method of foreground segmentation)#
   ![otsu](https://github.com/ghamrimohamedislam/BreastCancer/assets/124634951/35eb8177-983b-4f3a-afd0-0106d0ffa7ef)

# 2.2 Patch Extraction
Step 1 : Randomly extract patches (256 x 256) on the tissue region at the level of 40x

# Step 3 : Image Generator
Patches:

<img width="537" alt="M2" src="https://github.com/ghamrimohamedislam/BreastCancer/assets/124634951/255ec035-ca8b-4857-a3b1-f88e2d90a0de">

Ground Truth:

<img width="538" alt="M3" src="https://github.com/ghamrimohamedislam/BreastCancer/assets/124634951/3dea0321-061e-47b3-a846-c0406bb96873">

# 3 - Training Neural Network
# 3.1 FCN
Lambda, Normalize input (x / 255.0 - 0.5), outputs 256x256x3 
Convolution1, 5 x 5 kernel, stride 2, outputs 128x128x100
Maxpooling1, 2 x 2 window, stride 2, outputs 64x64x100
Convolution2, 5 x 5 kernel, stride 2, outputs 32x32x200
Maxpooling2, 2 x 2 window, stride 2, outputs 16x16x200
Convolution3, 3 x 3 kernel, stride 1, outputs 16x16x300
Convolution4, 3 x 3 kernel, stride 1, outputs 16x16x300
Dropout, 0.1 rate
Convolution5, 1x1 kernel, stride 1, outputs 16x16x2
Deconvolution, 31 x 31 kernel, stride 16, outputs 256x256x2
# 4 - Prediction and Evaluation
# 4.1 Make predictions and construct heatmaps
Test images were divided into non-overlapping small patches; each patch will get a predicted image for each pixel assigned by probability. Heatmap is a way to display the probability
Put all the patches together and get prediction for the whole slide.
<img width="1763" alt="heatmaps009" src="https://github.com/ghamrimohamedislam/BreastCancer/assets/124634951/d763c407-b06d-4c66-bee8-b891f1701b82">

# 4.2a Slide-based Classification
Extracting Features for whole-slide image classification task

# Global Features Extraction
The ratio between the area of metastatic regions and the tissue area.
The sum of all cancer metastases probailities detected in the metastasis identification task, divided by the tissue area. caculate them at 5 different thresholds (0.5, 0.6, 0.7, 0.8, 0.9), so the total 10 global features
# Local Features Extraction
Based on 2 largest metastatic candidate regions (select them based on a threshold of 0.5).

9 features were extracted from the 2 largest regions:

  Area: the area of connected region
  Eccentricity: The eccentricity of the ellipse that has the same second-moments as the region
  Extend: The ratio of region area over the total bounding box area
  Bounding box area
  Major axis length: the length of the major axis of the ellipse that has the same normalized second central moments as the region
  Max/mean/min intensity: The max/mean/minimum probability value in the region
  Aspect ratio of the bounding box
  Solidity: Ratio of region area over the surrounding convex area




